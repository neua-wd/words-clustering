{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "agricultural-chamber",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import jit, njit\n",
    "from nltk import pos_tag\n",
    "from nltk.cluster import KMeansClusterer, euclidean_distance, cosine_distance\n",
    "from nltk.corpus import brown, product_reviews_2\n",
    "import multiprocessing\n",
    "\n",
    "from DocumentBasedVectorizer import DocumentBasedVectorizer\n",
    "from ContextBasedVectorizer import ContextBasedVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "enormous-worse",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_words = ['abstraction', 'actually', 'add', 'address', 'answer',\n",
    "                'argument', 'arguments', 'back', 'call', 'car', 'case',\n",
    "                'cdr', 'computer', 'course', 'dictionary', 'different',\n",
    "                'evaluator', 'function', 'general', 'got', 'idea', 'kind',\n",
    "                'lambda', 'machine', 'mean', 'object', 'operator', 'order',\n",
    "                'pair', 'part', 'particular', 'pattern', 'place', 'problem',\n",
    "                'process', 'product', 'program', 'reason', 'register',\n",
    "                'result', 'set', 'simple', 'structure', 'system', 'they',\n",
    "                'together', 'using', 'variable', 'why', 'zero']\n",
    "\n",
    "tagged_target_words = pos_tag(target_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "comprehensive-admission",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
    "    sum = 0\n",
    "    for i in range(0, 5):\n",
    "        if (vectorizer_type == 'document'):\n",
    "            vectorizer = DocumentBasedVectorizer(target_words=target_words,\n",
    "                                                 corpus=corpus,\n",
    "                                                 tagged=tagged,\n",
    "                                                 weighting=weighting,\n",
    "                                                 stem=stem,\n",
    "                                                 lemmatize=lemmatize,\n",
    "                                                 remove_stopwords=remove_stopwords,\n",
    "                                                 for_evaluation=True)\n",
    "        else:\n",
    "            vectorizer = ContextBasedVectorizer(target_words=target_words,\n",
    "                                                corpus=corpus,\n",
    "                                                tagged=tagged,\n",
    "                                                stem=stem,\n",
    "                                                lemmatize=lemmatize,\n",
    "                                                remove_stopwords=remove_stopwords,\n",
    "                                                window_size=window_size,\n",
    "                                                for_evaluation=True)\n",
    "\n",
    "        vectors = vectorizer.vectorize()\n",
    "        clusterer = KMeansClusterer(50, euclidean_distance, avoid_empty_clusters=True)\n",
    "        clusterer.cluster_vectorspace(list(vectors.values()))\n",
    "\n",
    "        appended = []\n",
    "        for word in target_words:\n",
    "            appended.append(word)\n",
    "\n",
    "        for word in target_words:\n",
    "            appended.append(word[::-1])\n",
    "\n",
    "        vectors = list(vectors.values())\n",
    "        correct = 0\n",
    "        result = []\n",
    "        for i in range(0, len(target_words)):\n",
    "            word_vector = vectors[i]\n",
    "            reversed_word_vector = vectors[i + len(target_words)]\n",
    "            result.append([{appended[i]: clusterer.classify(word_vector)}, {appended[i + len(target_words)]: clusterer.classify(reversed_word_vector)}])\n",
    "            if (clusterer.classify(word_vector) == clusterer.classify(reversed_word_vector)):\n",
    "                correct += 1\n",
    "\n",
    "        sum += (correct / len(target_words)) * 100\n",
    "    \n",
    "    return sum / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "political-hardware",
   "metadata": {},
   "outputs": [],
   "source": [
    "jit_evaluate = jit()(evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "major-coordinator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: '64.0%',\n",
       " 3: '46.0%',\n",
       " 4: '36.0%',\n",
       " 5: '32.0%',\n",
       " 6: '32.0%',\n",
       " 7: '28.000000000000004%',\n",
       " 8: '26.0%',\n",
       " 9: '26.0%'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = {}\n",
    "for window_size in range(2, 11):\n",
    "    output[window_size] = str(jit_cluster_and_evaluate(window_size)) + '%'\n",
    "\n",
    "output\n",
    "# pool = multiprocessing.Pool(processes=multiprocessing.cpu_count())\n",
    "# manager = multiprocessing.Manager()\n",
    "# evaluation_result = manager.dict()\n",
    "\n",
    "# for window_size in range(2, 10):\n",
    "#     pool.apply_async(cluster_and_evaluate, args=(window_size, evaluation_result))\n",
    "\n",
    "# pool.close()\n",
    "# pool.join()\n",
    "    \n",
    "# evaluation_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affected-vehicle",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-3a156c67b650>:1: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"evaluate\" failed type inference due to: Untyped global name 'DocumentBasedVectorizer': Cannot determine Numba type of <class 'type'>\n",
      "\n",
      "File \"<ipython-input-3-3a156c67b650>\", line 5:\n",
      "def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "    <source elided>\n",
      "        if (vectorizer_type == 'document'):\n",
      "            vectorizer = DocumentBasedVectorizer(target_words=target_words,\n",
      "            ^\n",
      "\n",
      "  def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "<ipython-input-3-3a156c67b650>:1: NumbaWarning: \n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"evaluate\" failed type inference due to: Cannot determine Numba type of <class 'numba.core.dispatcher.LiftedLoop'>\n",
      "\n",
      "File \"<ipython-input-3-3a156c67b650>\", line 3:\n",
      "def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "    <source elided>\n",
      "    sum = 0\n",
      "    for i in range(0, 5):\n",
      "    ^\n",
      "\n",
      "  def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "/Users/worabodeedenvittaya/Library/Python/3.8/lib/python/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"evaluate\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
      "\n",
      "File \"<ipython-input-3-3a156c67b650>\", line 2:\n",
      "def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "    sum = 0\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/Users/worabodeedenvittaya/Library/Python/3.8/lib/python/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"<ipython-input-3-3a156c67b650>\", line 2:\n",
      "def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "    sum = 0\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "<ipython-input-3-3a156c67b650>:1: NumbaWarning: \n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"evaluate\" failed type inference due to: Untyped global name 'DocumentBasedVectorizer': Cannot determine Numba type of <class 'type'>\n",
      "\n",
      "File \"<ipython-input-3-3a156c67b650>\", line 5:\n",
      "def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "    <source elided>\n",
      "        if (vectorizer_type == 'document'):\n",
      "            vectorizer = DocumentBasedVectorizer(target_words=target_words,\n",
      "            ^\n",
      "\n",
      "  def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "/Users/worabodeedenvittaya/Library/Python/3.8/lib/python/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"evaluate\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"<ipython-input-3-3a156c67b650>\", line 3:\n",
      "def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "    <source elided>\n",
      "    sum = 0\n",
      "    for i in range(0, 5):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/Users/worabodeedenvittaya/Library/Python/3.8/lib/python/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"<ipython-input-3-3a156c67b650>\", line 3:\n",
      "def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "    <source elided>\n",
      "    sum = 0\n",
      "    for i in range(0, 5):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n"
     ]
    }
   ],
   "source": [
    "for window_size in range(2, 11):\n",
    "    average_accuracy = jit_evaluate(vectorizer_type='context',\n",
    "                                    target_words=target_words,\n",
    "                                    corpus=brown,\n",
    "                                    window_size=window_size)\n",
    "    print('(context based, brown corpus, window size = ' + window_size + 'words) average accuracy = ' + str(average_accuracy) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-world",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
