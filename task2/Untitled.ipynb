{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beginning-superintendent",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import jit, njit\n",
    "from nltk import pos_tag\n",
    "from nltk.cluster import KMeansClusterer, euclidean_distance, cosine_distance\n",
    "from nltk.corpus import brown, product_reviews_2\n",
    "import multiprocessing\n",
    "\n",
    "from DocumentBasedVectorizer import DocumentBasedVectorizer\n",
    "from ContextBasedVectorizer import ContextBasedVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "favorite-crisis",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_words = ['abstraction', 'actually', 'add', 'address', 'answer',\n",
    "                'argument', 'arguments', 'back', 'call', 'car', 'case',\n",
    "                'cdr', 'computer', 'course', 'dictionary', 'different',\n",
    "                'evaluator', 'function', 'general', 'got', 'idea', 'kind',\n",
    "                'lambda', 'machine', 'mean', 'object', 'operator', 'order',\n",
    "                'pair', 'part', 'particular', 'pattern', 'place', 'problem',\n",
    "                'process', 'product', 'program', 'reason', 'register',\n",
    "                'result', 'set', 'simple', 'structure', 'system', 'they',\n",
    "                'together', 'using', 'variable', 'why', 'zero']\n",
    "\n",
    "tagged_target_words = pos_tag(target_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "internal-trademark",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
    "    sum = 0\n",
    "    for i in range(0, 5):\n",
    "        if (vectorizer_type == 'document'):\n",
    "            vectorizer = DocumentBasedVectorizer(target_words=target_words,\n",
    "                                                 corpus=corpus,\n",
    "                                                 tagged=tagged,\n",
    "                                                 weighting=weighting,\n",
    "                                                 stem=stem,\n",
    "                                                 lemmatize=lemmatize,\n",
    "                                                 remove_stopwords=remove_stopwords,\n",
    "                                                 for_evaluation=True)\n",
    "        else:\n",
    "            vectorizer = ContextBasedVectorizer(target_words=target_words,\n",
    "                                                corpus=corpus,\n",
    "                                                tagged=tagged,\n",
    "                                                stem=stem,\n",
    "                                                lemmatize=lemmatize,\n",
    "                                                remove_stopwords=remove_stopwords,\n",
    "                                                window_size=window_size,\n",
    "                                                for_evaluation=True)\n",
    "\n",
    "        vectors = vectorizer.vectorize()\n",
    "        clusterer = KMeansClusterer(50, euclidean_distance, avoid_empty_clusters=True)\n",
    "        clusterer.cluster_vectorspace(list(vectors.values()))\n",
    "\n",
    "        appended = []\n",
    "        for word in target_words:\n",
    "            appended.append(word)\n",
    "\n",
    "        for word in target_words:\n",
    "            appended.append(word[::-1])\n",
    "\n",
    "        vectors = list(vectors.values())\n",
    "        correct = 0\n",
    "        result = []\n",
    "        for i in range(0, len(target_words)):\n",
    "            word_vector = vectors[i]\n",
    "            reversed_word_vector = vectors[i + len(target_words)]\n",
    "            result.append([{appended[i]: clusterer.classify(word_vector)}, {appended[i + len(target_words)]: clusterer.classify(reversed_word_vector)}])\n",
    "            if (clusterer.classify(word_vector) == clusterer.classify(reversed_word_vector)):\n",
    "                correct += 1\n",
    "\n",
    "        sum += (correct / len(target_words)) * 100\n",
    "    \n",
    "    return sum / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "surprised-intervention",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "\n",
    "jit_evaluate = jit()(evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "prostate-phenomenon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(document based, brown corpus, binary weighting) average accuracy = 43.2%\n",
      "(document based, brown corpus, tf weighting) average accuracy = 63.6%\n",
      "(document based, brown corpus, tfidf weighting) average accuracy = 66.0%\n"
     ]
    }
   ],
   "source": [
    "average_accuracy = jit_evaluate(vectorizer_type='document', target_words=target_words, corpus=brown, weighting='binary')\n",
    "print('(document based, brown corpus, binary weighting) average accuracy = ' + str(average_accuracy) + '%')\n",
    "\n",
    "average_accuracy = jit_evaluate(vectorizer_type='document', target_words=target_words, corpus=brown, weighting='term-frequency')\n",
    "print('(document based, brown corpus, tf weighting) average accuracy = ' + str(average_accuracy) + '%')\n",
    "\n",
    "average_accuracy = jit_evaluate(vectorizer_type='document', target_words=target_words, corpus=brown, weighting='tfidf')\n",
    "print('(document based, brown corpus, tfidf weighting) average accuracy = ' + str(average_accuracy) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "convinced-tissue",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-3a156c67b650>:1: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"evaluate\" failed type inference due to: Untyped global name 'DocumentBasedVectorizer': Cannot determine Numba type of <class 'type'>\n",
      "\n",
      "File \"<ipython-input-3-3a156c67b650>\", line 5:\n",
      "def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "    <source elided>\n",
      "        if (vectorizer_type == 'document'):\n",
      "            vectorizer = DocumentBasedVectorizer(target_words=target_words,\n",
      "            ^\n",
      "\n",
      "  def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "<ipython-input-3-3a156c67b650>:1: NumbaWarning: \n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"evaluate\" failed type inference due to: Cannot determine Numba type of <class 'numba.core.dispatcher.LiftedLoop'>\n",
      "\n",
      "File \"<ipython-input-3-3a156c67b650>\", line 3:\n",
      "def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "    <source elided>\n",
      "    sum = 0\n",
      "    for i in range(0, 5):\n",
      "    ^\n",
      "\n",
      "  def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "/Users/worabodeedenvittaya/Library/Python/3.8/lib/python/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"evaluate\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
      "\n",
      "File \"<ipython-input-3-3a156c67b650>\", line 2:\n",
      "def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "    sum = 0\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/Users/worabodeedenvittaya/Library/Python/3.8/lib/python/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"<ipython-input-3-3a156c67b650>\", line 2:\n",
      "def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "    sum = 0\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "<ipython-input-3-3a156c67b650>:1: NumbaWarning: \n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"evaluate\" failed type inference due to: Untyped global name 'DocumentBasedVectorizer': Cannot determine Numba type of <class 'type'>\n",
      "\n",
      "File \"<ipython-input-3-3a156c67b650>\", line 5:\n",
      "def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "    <source elided>\n",
      "        if (vectorizer_type == 'document'):\n",
      "            vectorizer = DocumentBasedVectorizer(target_words=target_words,\n",
      "            ^\n",
      "\n",
      "  def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "/Users/worabodeedenvittaya/Library/Python/3.8/lib/python/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"evaluate\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"<ipython-input-3-3a156c67b650>\", line 3:\n",
      "def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "    <source elided>\n",
      "    sum = 0\n",
      "    for i in range(0, 5):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/Users/worabodeedenvittaya/Library/Python/3.8/lib/python/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"<ipython-input-3-3a156c67b650>\", line 3:\n",
      "def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "    <source elided>\n",
      "    sum = 0\n",
      "    for i in range(0, 5):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(document based, brown corpus, tfidf weighting, stemmed) average accuracy = 79.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-3a156c67b650>:1: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"evaluate\" failed type inference due to: Untyped global name 'DocumentBasedVectorizer': Cannot determine Numba type of <class 'type'>\n",
      "\n",
      "File \"<ipython-input-3-3a156c67b650>\", line 5:\n",
      "def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "    <source elided>\n",
      "        if (vectorizer_type == 'document'):\n",
      "            vectorizer = DocumentBasedVectorizer(target_words=target_words,\n",
      "            ^\n",
      "\n",
      "  def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "<ipython-input-3-3a156c67b650>:1: NumbaWarning: \n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"evaluate\" failed type inference due to: Cannot determine Numba type of <class 'numba.core.dispatcher.LiftedLoop'>\n",
      "\n",
      "File \"<ipython-input-3-3a156c67b650>\", line 3:\n",
      "def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "    <source elided>\n",
      "    sum = 0\n",
      "    for i in range(0, 5):\n",
      "    ^\n",
      "\n",
      "  def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "/Users/worabodeedenvittaya/Library/Python/3.8/lib/python/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"evaluate\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
      "\n",
      "File \"<ipython-input-3-3a156c67b650>\", line 2:\n",
      "def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "    sum = 0\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/Users/worabodeedenvittaya/Library/Python/3.8/lib/python/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"<ipython-input-3-3a156c67b650>\", line 2:\n",
      "def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "    sum = 0\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "<ipython-input-3-3a156c67b650>:1: NumbaWarning: \n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"evaluate\" failed type inference due to: Untyped global name 'DocumentBasedVectorizer': Cannot determine Numba type of <class 'type'>\n",
      "\n",
      "File \"<ipython-input-3-3a156c67b650>\", line 5:\n",
      "def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "    <source elided>\n",
      "        if (vectorizer_type == 'document'):\n",
      "            vectorizer = DocumentBasedVectorizer(target_words=target_words,\n",
      "            ^\n",
      "\n",
      "  def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "/Users/worabodeedenvittaya/Library/Python/3.8/lib/python/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"evaluate\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"<ipython-input-3-3a156c67b650>\", line 3:\n",
      "def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "    <source elided>\n",
      "    sum = 0\n",
      "    for i in range(0, 5):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/Users/worabodeedenvittaya/Library/Python/3.8/lib/python/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"<ipython-input-3-3a156c67b650>\", line 3:\n",
      "def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "    <source elided>\n",
      "    sum = 0\n",
      "    for i in range(0, 5):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(document based, brown corpus, tfidf weighting, stemmed, lemmatized) average accuracy = 76.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-3a156c67b650>:1: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"evaluate\" failed type inference due to: Untyped global name 'DocumentBasedVectorizer': Cannot determine Numba type of <class 'type'>\n",
      "\n",
      "File \"<ipython-input-3-3a156c67b650>\", line 5:\n",
      "def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "    <source elided>\n",
      "        if (vectorizer_type == 'document'):\n",
      "            vectorizer = DocumentBasedVectorizer(target_words=target_words,\n",
      "            ^\n",
      "\n",
      "  def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "<ipython-input-3-3a156c67b650>:1: NumbaWarning: \n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"evaluate\" failed type inference due to: Cannot determine Numba type of <class 'numba.core.dispatcher.LiftedLoop'>\n",
      "\n",
      "File \"<ipython-input-3-3a156c67b650>\", line 3:\n",
      "def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "    <source elided>\n",
      "    sum = 0\n",
      "    for i in range(0, 5):\n",
      "    ^\n",
      "\n",
      "  def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "/Users/worabodeedenvittaya/Library/Python/3.8/lib/python/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"evaluate\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
      "\n",
      "File \"<ipython-input-3-3a156c67b650>\", line 2:\n",
      "def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "    sum = 0\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/Users/worabodeedenvittaya/Library/Python/3.8/lib/python/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"<ipython-input-3-3a156c67b650>\", line 2:\n",
      "def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "    sum = 0\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "<ipython-input-3-3a156c67b650>:1: NumbaWarning: \n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"evaluate\" failed type inference due to: Untyped global name 'DocumentBasedVectorizer': Cannot determine Numba type of <class 'type'>\n",
      "\n",
      "File \"<ipython-input-3-3a156c67b650>\", line 5:\n",
      "def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "    <source elided>\n",
      "        if (vectorizer_type == 'document'):\n",
      "            vectorizer = DocumentBasedVectorizer(target_words=target_words,\n",
      "            ^\n",
      "\n",
      "  def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "/Users/worabodeedenvittaya/Library/Python/3.8/lib/python/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"evaluate\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"<ipython-input-3-3a156c67b650>\", line 3:\n",
      "def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "    <source elided>\n",
      "    sum = 0\n",
      "    for i in range(0, 5):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/Users/worabodeedenvittaya/Library/Python/3.8/lib/python/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"<ipython-input-3-3a156c67b650>\", line 3:\n",
      "def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "    <source elided>\n",
      "    sum = 0\n",
      "    for i in range(0, 5):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(document based, brown corpus, tfidf weighting, stemmed, lemmatized, removed stopwords) average accuracy = 83.2%\n"
     ]
    }
   ],
   "source": [
    "average_accuracy = jit_evaluate(vectorizer_type='document',\n",
    "                                target_words=target_words,\n",
    "                                corpus=brown,\n",
    "                                weighting='tfidf',\n",
    "                                stem=True)\n",
    "print('(document based, brown corpus, tfidf weighting, stemmed) average accuracy = ' + str(average_accuracy) + '%')\n",
    "\n",
    "average_accuracy = jit_evaluate(vectorizer_type='document',\n",
    "                                target_words=target_words,\n",
    "                                corpus=brown,\n",
    "                                weighting='tfidf',\n",
    "                                stem=True,\n",
    "                                lemmatize=True)\n",
    "print('(document based, brown corpus, tfidf weighting, stemmed, lemmatized) average accuracy = ' + str(average_accuracy) + '%')\n",
    "\n",
    "average_accuracy = jit_evaluate(vectorizer_type='document',\n",
    "                                target_words=target_words,\n",
    "                                corpus=brown,\n",
    "                                weighting='tfidf',\n",
    "                                stem=True,\n",
    "                                lemmatize=True,\n",
    "                                remove_stopwords=True)\n",
    "print('(document based, brown corpus, tfidf weighting, stemmed, lemmatized, removed stopwords) average accuracy = ' + str(average_accuracy) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "liable-jason",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-3a156c67b650>:1: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"evaluate\" failed type inference due to: Untyped global name 'DocumentBasedVectorizer': Cannot determine Numba type of <class 'type'>\n",
      "\n",
      "File \"<ipython-input-3-3a156c67b650>\", line 5:\n",
      "def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "    <source elided>\n",
      "        if (vectorizer_type == 'document'):\n",
      "            vectorizer = DocumentBasedVectorizer(target_words=target_words,\n",
      "            ^\n",
      "\n",
      "  def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "<ipython-input-3-3a156c67b650>:1: NumbaWarning: \n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"evaluate\" failed type inference due to: Cannot determine Numba type of <class 'numba.core.dispatcher.LiftedLoop'>\n",
      "\n",
      "File \"<ipython-input-3-3a156c67b650>\", line 3:\n",
      "def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "    <source elided>\n",
      "    sum = 0\n",
      "    for i in range(0, 5):\n",
      "    ^\n",
      "\n",
      "  def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "/Users/worabodeedenvittaya/Library/Python/3.8/lib/python/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"evaluate\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
      "\n",
      "File \"<ipython-input-3-3a156c67b650>\", line 2:\n",
      "def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "    sum = 0\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/Users/worabodeedenvittaya/Library/Python/3.8/lib/python/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"<ipython-input-3-3a156c67b650>\", line 2:\n",
      "def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "    sum = 0\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "<ipython-input-3-3a156c67b650>:1: NumbaWarning: \n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"evaluate\" failed type inference due to: Untyped global name 'DocumentBasedVectorizer': Cannot determine Numba type of <class 'type'>\n",
      "\n",
      "File \"<ipython-input-3-3a156c67b650>\", line 5:\n",
      "def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "    <source elided>\n",
      "        if (vectorizer_type == 'document'):\n",
      "            vectorizer = DocumentBasedVectorizer(target_words=target_words,\n",
      "            ^\n",
      "\n",
      "  def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "/Users/worabodeedenvittaya/Library/Python/3.8/lib/python/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"evaluate\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"<ipython-input-3-3a156c67b650>\", line 3:\n",
      "def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "    <source elided>\n",
      "    sum = 0\n",
      "    for i in range(0, 5):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/Users/worabodeedenvittaya/Library/Python/3.8/lib/python/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"<ipython-input-3-3a156c67b650>\", line 3:\n",
      "def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "    <source elided>\n",
      "    sum = 0\n",
      "    for i in range(0, 5):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(document based, brown corpus, tfidf weighting, removed stopwords) average accuracy = 74.4%\n"
     ]
    }
   ],
   "source": [
    "average_accuracy = jit_evaluate(vectorizer_type='document',\n",
    "                                target_words=target_words,\n",
    "                                corpus=brown,\n",
    "                                weighting='tfidf',\n",
    "                                remove_stopwords=True)\n",
    "print('(document based, brown corpus, tfidf weighting, removed stopwords) average accuracy = ' + str(average_accuracy) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "differential-baseball",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-3a156c67b650>:1: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"evaluate\" failed type inference due to: Untyped global name 'DocumentBasedVectorizer': Cannot determine Numba type of <class 'type'>\n",
      "\n",
      "File \"<ipython-input-3-3a156c67b650>\", line 5:\n",
      "def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "    <source elided>\n",
      "        if (vectorizer_type == 'document'):\n",
      "            vectorizer = DocumentBasedVectorizer(target_words=target_words,\n",
      "            ^\n",
      "\n",
      "  def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "<ipython-input-3-3a156c67b650>:1: NumbaWarning: \n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"evaluate\" failed type inference due to: Cannot determine Numba type of <class 'numba.core.dispatcher.LiftedLoop'>\n",
      "\n",
      "File \"<ipython-input-3-3a156c67b650>\", line 3:\n",
      "def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "    <source elided>\n",
      "    sum = 0\n",
      "    for i in range(0, 5):\n",
      "    ^\n",
      "\n",
      "  def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "/Users/worabodeedenvittaya/Library/Python/3.8/lib/python/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"evaluate\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
      "\n",
      "File \"<ipython-input-3-3a156c67b650>\", line 2:\n",
      "def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "    sum = 0\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/Users/worabodeedenvittaya/Library/Python/3.8/lib/python/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"<ipython-input-3-3a156c67b650>\", line 2:\n",
      "def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "    sum = 0\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "<ipython-input-3-3a156c67b650>:1: NumbaWarning: \n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"evaluate\" failed type inference due to: Untyped global name 'DocumentBasedVectorizer': Cannot determine Numba type of <class 'type'>\n",
      "\n",
      "File \"<ipython-input-3-3a156c67b650>\", line 5:\n",
      "def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "    <source elided>\n",
      "        if (vectorizer_type == 'document'):\n",
      "            vectorizer = DocumentBasedVectorizer(target_words=target_words,\n",
      "            ^\n",
      "\n",
      "  def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "/Users/worabodeedenvittaya/Library/Python/3.8/lib/python/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"evaluate\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"<ipython-input-3-3a156c67b650>\", line 3:\n",
      "def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "    <source elided>\n",
      "    sum = 0\n",
      "    for i in range(0, 5):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/Users/worabodeedenvittaya/Library/Python/3.8/lib/python/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"<ipython-input-3-3a156c67b650>\", line 3:\n",
      "def evaluate(vectorizer_type, target_words, corpus, tagged=False, weighting='binary', window_size=10, stem=False, lemmatize=False, remove_stopwords=False):\n",
      "    <source elided>\n",
      "    sum = 0\n",
      "    for i in range(0, 5):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(document based, brown corpus, tfidf weighting, tagged, stemmed, lemmatized, removed stopwords) average accuracy = 48.0%\n"
     ]
    }
   ],
   "source": [
    "average_accuracy = jit_evaluate(vectorizer_type='document',\n",
    "                                target_words=tagged_target_words,\n",
    "                                corpus=brown,\n",
    "                                tagged=True,\n",
    "                                weighting='tfidf',\n",
    "                                stem=True,\n",
    "                                lemmatize=True,\n",
    "                                remove_stopwords=True)\n",
    "print('(document based, brown corpus, tfidf weighting, tagged, stemmed, lemmatized, removed stopwords) average accuracy = ' + str(average_accuracy) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-sacramento",
   "metadata": {},
   "outputs": [],
   "source": [
    "for window_size in range(2, 11):\n",
    "    average_accuracy = jit_evaluate(vectorizer_type='context',\n",
    "                                    target_words=target_words,\n",
    "                                    corpus=brown,\n",
    "                                    stem=True,\n",
    "                                    lemmatize=True,\n",
    "                                    remove_stopwords=True)\n",
    "    print('(context based, brown corpus, stemmed, lemmatized, removed stopwords, window size = ' + window_size + 'words) average accuracy = ' + str(average_accuracy) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-nickel",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
